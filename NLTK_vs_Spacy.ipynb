{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Spacy is Object Oriented and NLTK is string processing libry.NLTK (Natural Language Toolkit) and SpaCy are two popular NLP libraries, each with different use cases and efficiencies."
      ],
      "metadata": {
        "id": "PxDlpYyC08Y1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GYQ54Ru7zwE9"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a Packge for tokenizer for english word"
      ],
      "metadata": {
        "id": "NqHhHyma0Rf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "OtaqHUnFz1t2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the sentence"
      ],
      "metadata": {
        "id": "PL_77xRq0qio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = nlp('Your approach was correct in using Kahn’s Algorithm but had small issues in implementation. The fixed version properly initializes indegree, avoids errors, and ensures correctness.')\n",
        "for sentence in text.sents:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz4cvA940O3a",
        "outputId": "5d053b4f-ad72-473a-8bef-4770ba62fdc7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your approach was correct in using Kahn’s Algorithm but had small issues in implementation.\n",
            "The fixed version properly initializes indegree, avoids errors, and ensures correctness.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.sents:\n",
        "  for word in sentence:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpH--hEx0QSw",
        "outputId": "b90788d9-69be-4bac-8dde-8bc4fc1732ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your\n",
            "approach\n",
            "was\n",
            "correct\n",
            "in\n",
            "using\n",
            "Kahn\n",
            "’s\n",
            "Algorithm\n",
            "but\n",
            "had\n",
            "small\n",
            "issues\n",
            "in\n",
            "implementation\n",
            ".\n",
            "The\n",
            "fixed\n",
            "version\n",
            "properly\n",
            "initializes\n",
            "indegree\n",
            ",\n",
            "avoids\n",
            "errors\n",
            ",\n",
            "and\n",
            "ensures\n",
            "correctness\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RK7PkfL1wUp",
        "outputId": "9ba0c1f9-17e3-4080-f5d7-dddc47b468b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Download the required NLTK models\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # This line was added to download the missing data package.\n",
        "\n",
        "\n",
        "text = (\"Your approach was correct in using Kahn’s Algorithm but had small issues in implementation. \"\n",
        "        \"The fixed version properly initializes indegree, avoids errors, and ensures correctness.\")\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD3uB46d1gRv",
        "outputId": "fb4adabb-74eb-469b-b49d-b195ff3b0adf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Your approach was correct in using Kahn’s Algorithm but had small issues in implementation.', 'The fixed version properly initializes indegree, avoids errors, and ensures correctness.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the required NLTK models\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # This line was added to download the missing data package.\n",
        "\n",
        "\n",
        "text = (\"Your approach was correct in using Kahn’s Algorithm but had small issues in implementation. \"\n",
        "        \"The fixed version properly initializes indegree, avoids errors, and ensures correctness.\")\n",
        "\n",
        "words = word_tokenize(text)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75VcqNgM2Ivy",
        "outputId": "7adde4a8-7e4d-4e4b-bc35-3b92161f9c76"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Your', 'approach', 'was', 'correct', 'in', 'using', 'Kahn', '’', 's', 'Algorithm', 'but', 'had', 'small', 'issues', 'in', 'implementation', '.', 'The', 'fixed', 'version', 'properly', 'initializes', 'indegree', ',', 'avoids', 'errors', ',', 'and', 'ensures', 'correctness', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}